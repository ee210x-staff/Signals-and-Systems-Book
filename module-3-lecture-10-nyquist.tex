\section{Lecture 10: Nyquist Sampling Theorem: Proof and Application}

\subsection{Introduction}
Till now, we have talked about ``ideal'' sampling, where the sampling was done using impulses. We have also done sampling using \emph{pulses}, instead of impulses. In this lecture, we will look at a ``generalized version'' of the sampling, which is called ``amplitude modulation''.  We will also prove a more general form of the Nyquist-Shannon sampling theorem.


%signals, that is, you only ``read'' and ``store'' the value of the signal at certain points. We saw the problems associated with sampling, mainly the fact that given just the sampled signal, it is not possible to reconstruct the original signal, because there are many possible signals which would have given the \emph{same} samples, i.e. they would have taken on the same values as this signal at the points where we are sampling. The natural question to ask, then, is what ``extra information'' do we need in order to reconstruct the original signal from this sample? To do that, we first have to know what these ``other signals'' look like.

\subsection{General form of the Nyquist-Shannon Sampling Theorem}
We have looked at sampling in some detail in the previous lectures. We will now generalize this idea of sampling. Earlier, for ``ideal'' we multiplied the signal with a train of impulses placed at regular intervals. Now, what we are going to do is that we will multiply the signal with any ``carrier signal'' $p(t)$, and the only requirement that we are going to make of $p(t)$ is that it be periodic with period $T_s$. This signal, as a result of this periodicity, will have a complex Fourier series expansion:
\[ p(t) = \sum\limits_{k=-\infty}^{+\infty} c_k e^{\imath\frac{2\pi}{T_s}kt}\]
Let the signal to be ``sampled'' be $x(t)$, and I put the word ``sampled'' in quotes because what we're doing here can't really be called sampling. We need $x(t)$ to have a Fourier transform $X(\Omega)$. Now we ``sample'' this $x(t)$ using $p(t)$, (which is to say we multiply the two) to obtain $x(t) p(t)$. The Fourier Transform of this $x(t) p(t)$ is $X_s(\Omega)$ (say).

\begin{align*}
X_s(\Omega)&=\mathcal{F}\left(x(t) p(t)\right)\\
&=\mathcal{F}\left(x(t) \sum\limits_{k=-\infty}^{+\infty} c_k e^{\imath\frac{2\pi}{T_s}kt}\right)\\
&=\sum\limits_{k=-\infty}^{+\infty}c_k\mathcal{F}\left(x(t) e^{\imath\frac{2\pi}{T_s}kt}\right) \tag{$k$ is independent of $t$}\\
&=\sum\limits_{k=-\infty}^{+\infty}c_k X\left(\Omega-\frac{2\pi}{T_s}k\right)
\end{align*}
As an example, let's see what happens with $p(t)=A_c\cos\left(\frac{2\pi}{T_s}t\right)$, which can also be written as
\[p(t)=\frac{A_c}{2}\left(e^{\imath\frac{2\pi}{T_s}t} + e^{-\imath\frac{2\pi}{T_s}t}\right)\]
Thus, we have
\[X_s(\Omega)=\frac{A_c}{2}\left\{ X\left(\Omega-\frac{2\pi}{T_s}\right)+ X\left(\Omega+\frac{2\pi}{T_s}\right)\right\}\]
And this is \emph{precisely} what is known as \emph{amplitude modulation}. This $p(t)=A_c\cos\left(\frac{2\pi}{T_s}t\right)$ is called the \emph{carrier wave}, and $x(t)$ is said to have been modulated with this carrier. This modulation has the effect of creating two copies of the signal and shifting each one of them forward and backward respectively, in the frequency domain. And if the carrier frequency is large enough, these two copies don't ``overlap'' (or ``mix'') with each other.

Therefore, in applying the Nyquist theorem, we have essentially carried out amplitude modulation (instead of sampling, as is usually done).

It's worthwhile to note that we need not have used a pure sinusoid to modulate the signal. In fact, as we have stated before, we could have used any periodic signal! This is important when we start designing and building systems (say electronic circuits), as it is difficult to build systems like multipliers and sinusoid generators, which are necessary for amplitude modulation with pure sinusoids. %And the above example gives us an idea as to how we can go about doing it.

Instead, a much simpler way to do modulation is to just use a train of pulses. It is easy to see that modulation using a pulse train (which is essentially just multiplication with said pulse train) is equivalent to just switching the signal on and off (and scaling it) at regular intervals! And building such a circuit would be much easier.

So we choose $p(t)$ to be a pulse train of period $T_s$, having pulse width $\Delta$ and height $\frac{1}{\Delta}$. Doing this, we obtain a spectrum as shown in Figure~\ref{fig:pulsemodspectrum}. As we can see, the first two carbon copies (the ones corresponding to $c_1$ and $c_{-1}$) are the ones we want, as they are the ones that appear in the usual amplitude modulation with a sinusoid.

We want to retain only the ``carbon copies'' corresponding to  $c_1$ and $c_{-1}$ and get rid of the $c_0$, $c_2$ and $c_{-2}$, $c_3$ and $c_{-3}$\ldots terms. To do that, we use a \emph{band-pass filter} as shown in Figure~\ref{fig:bandpassspectrum}.

A band pass filter, as the name suggests, only allows a certain \emph{range} of frequencies to go through, and \emph{blocks} all other frequencies. An ideal band-pass filter has a frequency response of $G$ in the \emph{passband} (the range of frequencies to be passed) and $0$ in the \emph{stop-band} (everywhere except the passband). The frequency response of a more \emph{practical} band pass filter is shown in Figure~\ref{fig:practpassband}. The frequencies at the boundary of the passband and stop band form the transition band. In this region, the impulse response undergoes a smooth transition. In a practical bandpass filter, you can't make the frequency response in the passband constant, you can't make the frequency response in the stop band exactly zero, and you can't make the transition band infinitesimally small.

Therefore, this filter \emph{will} pass parts of the other copies of the original spectrum, but these will be \emph{attenuated} (scaled down). Broadly speaking, this is how amplitude modulation is done, in practice.

