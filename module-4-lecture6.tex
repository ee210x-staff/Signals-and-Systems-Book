\section{Module 4: Lecture 6\\Dealing with Poly Ex Terms and Partial Fraction Expansion}

\subsection{Introduction}
In the previous session you were introduced to the Systems function for LSI systems which is essentially defined as the ratio of the Laplace transform of the output function to the input function for continuous time variable systems and ratio of Z-transform of the output function to the input function for the discrete time variable system. The impulse response of most of the natural engineering systems is typically a linear combination of “Poly ex” terms. In this session you are going to learn about how to evaluate the Laplace Transform of “Poly ex” functions using the Differentiation property of Laplace transform. We will also discuss about how to evaluate the Laplace inverse of a product of factors using Partial fraction expansion method. 
\subsection{Polynomial exponential function}
The “Poly Ex” function is as the name suggests Polynomial multiplied by Exponential function. For example, $(2t^3+3t+5) e^{-4t}u(t)$.\\
The general form of the Poly ex function can be written as $(\sum_{l=0}^{l=M} a_l t^l )e^{-\alpha t} u(t)$
Here our exponential parameter $\alpha$ can be real or complex i.e.  $\alpha= \alpha_R+ j \alpha_I$ where $\alpha_R$ the is real part of $\alpha$ which is alright; whereas $\alpha_I$  is the imaginary part of $\alpha$ which would give you the complex part in the expression. If the overall impulse response is real then $\alpha$ must come together with $\alpha$ complex conjugates so in other words if you have one term of this form then you must have another term of the form $(\sum_{l=0}^{l=M} a_l t^l )e^{-\bar{\alpha} t} u(t)$.\\
Here we have taken right sided function $u(t)$ which is $0$ up to $t=0$ and then equal to unity for all $t > 0$. But you can also take a left sided function i.e. $u(-t)$ which is equal to unity for all $t < 0$ and then $0$ for all $t > 0$. In general we may take any of right or left sided Poly ex function and also we can take our zero at any point on $t-$axis i.e. $u(t-t_0)$ which is equal to $0$ up to $t = t_0$ and then equal to $1$. You can fix the zero where you like but you can't do it if there are multiple Poly ex terms because you may not have this same point from which they start. So the statement that you can fix your zero where you like is meaningful to the extent that you are dealing with just one term. So you could have right sided or left sided signals, unfortunately you cannot have signals that last all over time; we saw that, if you had $e{^2t}$  for all $t$ it has no Laplace transform, in the general sense of Laplace transforms using functions you are not using impulses and things like that. If one wants to deal with functions in the $s$ plane or in the $Z$ plane then exponentials lasting all over time have no Laplace transform or Z-transform. So you need either left sided or right sided signals.

\subsection{Differentiation property for Laplace transform}

You know how to invert the Laplace transforms of the form  $\frac{1}{(s+\alpha)}$ . These kind of things we have been doing extensively. What would be the Laplace inverse if we multiply this kind of functions $\frac{1}{(s+\alpha)}$ by a polynomial? For a polynomial of degree $0$ (a constant) there is no problem; but what if we multiply it by $t$ or $t^2$? For that we need to establish our next property called property of differentiation for Laplace transform.\\
Let $x(t)$ has the Laplace transform $X(s)$ with a Region of Convergence(ROC)  $R_x$. The question is what would be the Laplace inverse if we differentiate $X(s)$ in the $s$ domain with almost the same ROC $R_x$ except some isolated contours. 
Let’s write down $X(s)$ in terms of $x(t)$ and then differentiate both sides with respect to $s$,
\[
X(s)=\int_{-\infty}^{\infty} \! x(t)e^{-st} \ \dm t, \ ROC : R_x
\]
\[
\frac{\dm X(s)}{\dm s}=\int_{-\infty}^{\infty} \! (-t)x(t)e^{-st} \ \dm t \ ROC : R_x
\]
Here, we are assuming that $X(s)$ is differentiable with respect to $s$ and we can take the derivative inside the integral on the integrand which is a function of $s$.
Now, multiply both sides by $-1$ and see now we have the Laplace transform of $t.x(t)$ which is just negative of the derivative of Laplace transform of $x(t)$.
\[
-\frac{\dm X(s)}{\dm s}=\int_{-\infty}^{\infty} \! (t.x(t))e^{-st} \ \dm t \ ROC : R_x
\]
For example, let's find the Laplace transform of $te^{-3t} u(t)$.\\
You know the Laplace transform of $e^{-3t} u(t)$ which is $\frac{1}{(s+3)}$. So by using the property of differentiation we just derived, it should be $-\frac{\dm(\frac{1}{(s+3)})}{\dm s} = \frac{1}{(s+3)^2}$.
Now we are quite equipped to deal with the Laplace transform of Poly ex terms. Let’s put down a procedure. Let’s take the example which we took earlier.
\[ x(t)=(\sum_{l=0}^{l=M} a_l t^l )e^{-\alpha t} u(t) \]

Laplace transform of this is equal to the sum of individual Laplace transforms of each term which can be calculated using the differentiation property repeatedly.
Let’s take Laplace transform of a general term  $a_l t^l e^{-\alpha t} u(t)$.
Laplace transform of $e^{-\alpha t} u(t)$  is   $\frac{1}{(s+\alpha)}$ (take it as $F(s)$). After multiplying by $t$ it should be $-\frac{\dm F(s)}{\dm s}$ and so after multiplied by $t$ repeatedly for $l-1$ times it would be $(-1)^l \frac{\dm^l F(s)}{\dm s^l}$. Also the multiplication by a constant is not a big deal since Laplace transform follows the homogeneity principle. So the final expression for the Laplace transform of a Poly ex function $x(t)$ can be written as follows:
\[
X(s)=\sum_{l=0}^{M}\frac{a_l  l!}{(s+\alpha)^{l+1}} 
\]
\subsection{Region of Convergence}
Using the differentiation property we are able to deal with Laplace transforms of the form $\frac{1}{(s+\alpha)^M}$  (where $M$ is a positive integer) with $Re(s+\alpha) > 0$ or $Re(s+\alpha) < 0$. We have two different possible regions of convergence for $Re(s+\alpha) > 0$ and  $Re(s+\alpha) < 0$. There is a very simple principle to associate these with the so called right sided and left sided signals. In the complex plane there are two explicit regions comprising $Re(s) > Re(-\alpha)$ and $Re(s) < Re(-\alpha)$; both are separated by a critical line $Re(s) = Re(- \alpha)$. You know that for existence of the Laplace transform, the input Poly ex signal should be either right sided or left sided. Here the rule is simple; the right side region of convergence corresponds to the right sided signal and the left side region of convergence corresponds to the left sided input signal i.e. if the input signal is something multiplied by $u(t)$ then ROC should be $Re(s) > Re(-\alpha)$. Also for right or left sided signal the shifting in time does not affect the ROC.\\
Now, what happens when Laplace transform has more than one such term? Let's look at that possibility now. Suppose Laplace transform is of the following form $\frac{1}{(s+\alpha)(s+\beta)}$,  obviously with $\alpha \neq  \beta$. Here there are three possible regions of convergence : $Re(s) < Re(-\alpha)$, $Re(-\alpha) < Re(s) < Re(-\beta)$ and $Re(s) > Re(-\beta)$ (assuming $Re(-\alpha) < Re(-\beta)$); which are separated by two critical vertical lines  $Re(s) = Re(- \alpha)$ and $Re(s) = Re(-\beta)$. It is very clear that taking any one region of convergence it falls into one of those two possible regions of convergence with respect to a specific vertical line. You can break this Laplace transform into terms that contains only one of these vertical lines by using Partial fraction expansion method.

\subsection{Partial Fraction Expansion}
The Laplace transform $X(s) = \frac{1}{(s+\alpha)(s+\beta)}$ is expected to be of the form $\frac{A}{(s+\alpha)} + \frac{B}{(s+\beta)}$. It’s very simple to determine the constants $A$ and $B$ here. Let
\[
X(s) = \frac{1}{(s+\alpha)(s+\beta)} = \frac{A}{(s+\alpha)} + \frac{B}{(s+\beta)}
\]

Now, multiply both the sides by $(s+\alpha)$, then it is
\[
\frac{1}{(s+\beta)} = A + \frac{B(s+\alpha)}{(s+\beta)}
\]
Now, put $s = - \alpha$ , so we get $A = \frac{1}{(\beta-\alpha)}$. Similarly you can find $ B = \frac{1}{(\alpha-\beta)}$.\\

So, you when we have simple factors like this there is no problem; Partial fraction is simple. But what do we do when we have multiple factors? So, let’s see that case too.
You could have $X(s) = \frac{1}{(s+\alpha)^2(s+\beta)}$. In this case there are several ways to decompose this into partial fractions, but here the type we wish to use is of the form
\[
X(s) = \frac{1}{(s+\alpha)^2(s+\beta)} = \frac{A}{(s+\alpha)} + \frac{B}{(s+\beta)} + \frac{C}{(s+\alpha)^2}
\]
Here, to find $B$ and $C$ is not a big deal; to find $B$ multiply both the sides by $s+\beta$ and then put $s = - \beta$ in the equation. Similarly, to find $C$ multiply both sides by $(s+\alpha)^2$ and then put $s = -\alpha$ in the equation. But to find $A$ we have to do something different.\\

After multiplying both sides by $(s+\alpha)^2$,
\[
\frac{1}{(s+\beta)} = A(s+\alpha) + \frac{B(s+\alpha)^2}{(s+\beta)}+C
\]
Now, we need to differentiate both sides with respect to $s$ and then put $s = -\alpha$. So the terms containing $B$ and $C$ will vanish and only the term containing $A$ would survive. After doing so you will get $A = -\frac{1}{(\beta-\alpha)^2}$ and of course, $B$ and $C$ will be respectively $\frac{1}{(\alpha-\beta)^2}$  and $\frac{1}{(\beta-\alpha)}$.

\subsection{Conclusion}
So now we have well equipped to study the Laplace transform of a “poly ex” term, so at least we are now competent to deal with a large number of engineering systems which have such impulse responses. All the typical electrical networks or mechanical systems using masses and frictional parts and springs would typically have these kinds of responses. So it's very clear that we now know how to recognize what happens when you have a square or a cube.\\
We can find the Laplace inverse of a product of factors easily after decomposing it into the terms of the form $\frac{A}{(s+\alpha)^n}$ which is the Laplace transform of a Poly ex function i.e. $\frac{A t^n e^{-\alpha t}}{n!}  u(t)$.
