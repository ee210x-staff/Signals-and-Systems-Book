\section{Lecture 17: Properties of the Convolution Operator}

\subsection{Introduction}
In the previous lecture, we looked at convolution, we also studied an example of the convolution of two very simple signals in detail. Here, we will look at two of the major properties of this operator, namely Commutativity and Associativity.

\subsection{Commutativity}

A binary operator (any operator that takes two operands and produces a result) is said to be commutative if changing the order of the operands does not change the result. For example, addition is commutative (e.g. $5+3=8=3+5$), but subtraction is not (e.g. $5-3\neq 3-5$).

\vspace{\baselineskip}
We are now in a position to prove the commutativity of convolution:

\begin{theorem}
Convolution is commutative, $x\ast y=y\ast x$.
\end{theorem}
\begin{proof}
\begin{case}
Signals are discrete
\end{case}
The convolution of two discrete signals $x[n]$ and $y[n]$ is defined as:
\begin{equation}
\label{eqn:discdef}
\left(x \ast y\right)[n] = \sum_{k=-\infty}^{+\infty} x[k]\ y[n-k]
\end{equation}

Note that this equation is true $\forall n$. Substitute $n-k=l$ (which also implies $k=n-l$) in Equation~\ref{eqn:discdef}. For any given $n$, as $k$ takes all the integral values from $-\infty$ to $+\infty$, $l=n-k$ also takes all the integral values, albeit in reverse order. Since the order in which we add the terms does not matter, we get:
\begin{equation}
\left(x \ast y\right)[n] = \sum_{l=-\infty}^{+\infty} x[n-l]\ y[l]
\end{equation}
which, if you look carefully at it, is really $(y \ast x)[n]$!
\begin{case}
Signals are continuous
\end{case}
The convolution of two continuous signals $x(t)$ and $y(t)$ is:
\begin{equation}
\label{eqn:contdef}
(x\ast y)(t) =\int\limits_{\tau=-\infty}^{+\infty} x(\tau)\ y(t-\tau)\ d\tau
\end{equation}

Substitute $t-\tau =\alpha$. Here, the order does matter. For any fixed $t$, as $\tau$ varies from $-\infty$ to $+\infty$, $\alpha=t-\tau$ varies from $+\infty$ to $-\infty$. Also, since $\alpha=t-\tau$, $d\alpha=-d\tau$. This gives us:

\begin{equation}
(x\ast y)(t) =\int\limits_{\alpha=+\infty}^{-\infty} x(t-\alpha)\ y(\alpha)(-d\alpha)
\end{equation}

By reversing the order of the order of integration, we get rid of the $-$ sign. Thus:
\begin{equation}
(x\ast y)(t) =\int\limits_{\alpha=-\infty}^{+\infty} x(t-\alpha)\ y(\alpha)\ d\alpha
\end{equation}
This is nothing but $(y\ast x)(t)$.
\end{proof}

\subsection{Associativity}

A binary operator is said to be associative if changing the order in which the operation is done on a sequence of (2 or more) operands (keeping the order of operands fixed), does not change the result. For example, multiplication is associative: $(2\times 3)\times 5=30=2\times (3\times 5)$, but division is not: $\left[\frac{(\frac{2}{4})}{5}=\frac{1}{10}\right] \neq
\left[\frac{2}{(\frac{4}{5})} = \frac{5}{2}\right]$.

\vspace{\baselineskip}
We can now prove that convolution is associative

\begin{theorem}
Convolution is Associative, $(x\ast y)\ast z = x\ast (y\ast z)$
\end{theorem}

\begin{proof}
\begin{case}
Signals are discrete
\end{case}
\begin{align}
 \left((x\ast y)\ast z\right)[n] &= \sum_{l=-\infty}^{+\infty}(x\ast y)[l]\ z[n-l] \\
  &= \sum_{l=-\infty}^{+\infty}z[n-l]\ \left(\sum_{k=-\infty}^{+\infty} x[k]\ y[l-k]\right) \nonumber\\
  &= \sum_{k,l=-\infty}^{+\infty}x[k]\ y[l-k]\ z[n-l] \nonumber\\
  &\text{(This is true because $l$ and $k$ vary independently)} \nonumber\\
  &\text{(Substitute $k=l_1 ,\ l-k=k_1 \implies n-l=n-l_1-k_1$)} \nonumber\\
  &= \sum_{l_1,k_1=-\infty}^{+\infty}x[l_1]\ y[k_1]\ z[n-l_1-k_1] \nonumber\\
  &= \sum_{l_1=-\infty}^{+\infty}x[l_1] \left( \sum_{k_1=-\infty}^{+\infty} y[k_1]\ z[(n-l_1)-k_1]\right) \nonumber\\
  &\text{(This is true because $l_1$ and $k_1$ vary independently)} \nonumber\\
  &= \sum_{l_1=-\infty}^{+\infty}x[l_1]\ (y\ast z)[n-l_1] \nonumber\\
 &= \left(x\ast (y\ast z)\right)[n]
\end{align}

\pagebreak
\begin{case}
Signals are continuous
\end{case}
\begin{align}
 \left((x\ast y)\ast z\right)(t) &= \int\limits_{\alpha=-\infty}^{+\infty}(x\ast y)(\alpha)\ z(t-\alpha)\ d\alpha \\
  &= \int\limits_{\alpha=-\infty}^{+\infty}z(t-\alpha)\ \left(\ \int\limits_{\lambda=-\infty}^{+\infty} x(\lambda)\ y(\alpha-\lambda)\ d\lambda\right)\ d\alpha \nonumber\\
  &= \iint\limits_{-\infty\,-\infty}^{+\infty\,+\infty} x(\lambda)\ y(\alpha-\lambda)\ z(t-\alpha)\ d\lambda\ d\alpha \nonumber\\
  &\text{This is an integration over 2 dimensions. Perform coordinate transformation:} \nonumber\\
  &\text{$\bigl[\begin{smallmatrix} \alpha_1\\ \lambda_1 \end{smallmatrix} \bigr] = \bigl[\begin{smallmatrix} 1&0\\ -1&1 \end{smallmatrix} \bigr]\ \bigl[\begin{smallmatrix} \lambda\\ \alpha \end{smallmatrix} \bigr]$ \ , ($\alpha_1=\lambda ,\ \lambda_1=\alpha -\lambda$). The limits don't change, here.} \nonumber\\
  &\text{The Jacobian of this transformation is $\bigl|\begin{smallmatrix} 1&0\\ -1&1 \end{smallmatrix} \bigr|=1 \implies d\lambda\ d\alpha =1 \times d\alpha_1\ d\lambda_1$} \nonumber\\
  &= \iint\limits_{-\infty\,-\infty}^{+\infty\,+\infty} x(\alpha_1)\ y(\lambda_1)\ z(t-\lambda_1-\alpha_1)\ d\alpha_1\ d\lambda_1 \nonumber\\
  &= \iint\limits_{-\infty\,-\infty}^{+\infty\,+\infty} x(\alpha_1)\ y(\lambda_1)\ z(t-\lambda_1-\alpha_1)\ d\lambda_1\ d\alpha_1\ \ \text{ (By Fubini's Theorem)}\nonumber\\
  &= \int\limits_{\alpha_1=-\infty}^{+\infty} x(\alpha_1)\left(\ \int\limits_{\lambda_1=-\infty}^{+\infty} y(\lambda_1)\ z((t-\alpha_1)-\lambda_1)\ d\lambda_1\right)d\alpha_1 \nonumber\\
  &\text{(This is true because $\alpha_1$ and $\lambda_1$ vary independently)} \nonumber\\
  &= \int\limits_{\alpha_1=-\infty}^{+\infty}x(\alpha_1)\ (y\ast z)(t-\alpha_1)\ d\alpha_1 \nonumber\\
 &= \left(x\ast (y\ast z)\right)(t)
\end{align}
\end{proof}

\subsection{Consequences of Commutativity and Associativity of Convolution}

Consider n LSI systems $S_1,S_2,S_3,\ldots,S_n$, having impulse responses $h_1,h_2,h_3,\ldots,h_n$, respectively. Suppose we cascade these n systems together, i.e. we give the input $x$ to $S_1$, take its output and give it to $S_2$, then take \emph{its} output and give it to $S_3$ and so on and so forth until we finally give the output of $S_{n-1}$ to $S_n$. We call the output of $S_n$, the "final" output,  $y$. By definition, 
\begin{equation}
y = \left(\left(\left(\left(x \ast h_1\right)\ast h_2\right)\ast h_3\right)\cdots\ast h_n\right)
\end{equation}
However, using associativity repeatedly, we can show that
\[y = \left(x \ast \left(\left(\left(h_1\ast h_2\right)\ast h_3\right)\cdots\ast h_n\right)\right)\]
Once this has been done, we use commutativity and assocativity repeatedly and show that, 
\[\left(\left(\left(h_1\ast h_2\right)\ast h_3\right)\cdots\ast h_n\right)=\left(\left(\left(h_{i_1}\ast h_{i_2}\right)\ast h_{i_3}\right)\cdots\ast h_{i_n}\right)\]
where $h_{i_1},h_{i_2},h_{i_3},\ldots ,h_{i_n}$ is any permutation of $h_1,h_2,h_3,\ldots,h_n$. This proves the fact that the cascade of these $n$ systems can be \emph{replaced by a single system} having an impulse response
\begin{equation}
h\equiv \left(h_1\ast h_2 \ast h_3\cdots\ast h_n\right)
\end{equation}
Here, the expression on the right hand side makes sense only because we have proved that a series of convolutions can be computed in any order. This is a very profound statement, because it means that the order in which the $n$ systems are cascaded \emph{does not affect the output}. The output will depend only on the input, and not on the order in which the systems are arranged.

